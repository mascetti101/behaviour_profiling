import sys
import math

from sklearn.cluster import KMeans

class dp_means():
	def __init__(self, _X, _k = 1, _lam = 1, _stop=False):
		self.lam = _lam
		self.nFeatures = len(_X[0])
		self.size = len(_X)
		self.X = _X
		self.stop = _stop
		# Initialize group memebership
		self.dataClusterId = [-1 for i in range(0, self.size)] # index of group for each data pair
		self.clusters = {}
		# output records
		self.record = []
		self.errorRecord = []
		self.k = _k

	def dSquared(self, x, y):
		dist2 = 0.0
		for j,k in zip(x,y):
			dist2 += (j - k)**2
		return dist2

	def error(self):
		res = 0.0
		for i in range(0, self.size):
			res += self.dSquared(self.X[i], self.clusters[self.dataClusterId[i]])
		return res/self.size

	def nearestCluster(self, x):
		cmin = sys.maxint
		cidx = -sys.maxint
		for j in self.clusters:
			dist = math.sqrt(self.dSquared(x, self.clusters[j]))
			if dist < cmin:  # record closest centroid
				cmin = dist
				cidx = j
		return cidx, cmin

	def assign(self):
		for i in range(0, self.allSize):
			self.dataClusterId[i], dmin = self.nearestCluster(self.X[i])

	def updateClusters(self):
		ctemp = {} # dim sums by cluster
		for j in range(0, self.k):
			ctemp[j] = []
			for k in range(0, self.nFeatures):
				ctemp[j].append(0.0) # init sums
			ctemp[j].append(0) # init counter
		# only calculate clusters on training, not cross-validation set
		for i in range(0,self.size):
			for j in range(0, self.nFeatures):
				ctemp[self.dataClusterId[i]][j] += self.X[i][j]
			ctemp[self.dataClusterId[i]][self.nFeatures] += 1 # count
		for c in self.clusters:
			if ctemp[c][self.nFeatures] <> 0:
				self.clusters[c] = [ ctemp[c][k]/ctemp[c][self.nFeatures] for k in range(0,self.nFeatures)]
			else:
				# no members in this cluster
				pass
		return

	def assign(self):
		for i in range(0, self.size):
			cidx, dmin = self.nearestCluster(self.X[i])
			if dmin > self.lam:
				self.k += 1
				self.clusters[self.k-1] = self.X[i]
				self.dataClusterId[i] = self.k - 1
			else:
				self.dataClusterId[i] = cidx

	def run(self, nmax = 100, eps = 1e-7):
		prev = 0.0
		prevXVal = float(sys.maxint)
		for iter in range(0, nmax):
			# update assignments
			self.assign()
			# calculate error
			err = self.error()
			#
			if abs(err-prev) < eps:
				sys.stderr.write("Tolerance reached at step %d\n"%iter)
				break
			prev = err
			# going on...
			self.errorRecord.append((iter, err))
			self.output(str(iter))
			self.updateClusters()
		sys.stderr.write("Iterations completed: %d\n"%iter)
		sys.stderr.write("Final error: %f\n"%prev)
		sys.stderr.write("Final cross-validation error: %f\n"%prevXVal)
		# This is a step past stop if using cross-validation...
		self.output("Final")
		return err

	def output(self, iter):
		for i in range(0,self.size):
			self.record.append([str(y) for y in self.X[i]] + [str(self.dataClusterId[i])] + ["Iter-%s"%iter])
		for k in self.clusters:
			self.record.append([str(y) for y in self.clusters[k]] + [str(k)] + ["Cent-Iter-%s"%iter])

	def getOutput(self):
		for x in self.record:
			yield x

	def getErrors(self):
		for x in self.errorRecord:
			yield x

def main():

	from data_import.ImportDataset import ImportData

	importer = ImportData('C:/Users/Paolo/Desktop/Reply/Thesis/Data/XsenseData/MT_07700161-003-001.txt')
	data = importer.import_csv()
	X =importer.get_clustering_table(data)
	# estimators_kmeans = {'k_means_10': KMeans(n_clusters=10),
	# 			  'k_means_15': KMeans(n_clusters=15),
	# 			  'k_means_20': KMeans(n_clusters=20)}
	# for name, est in estimators_kmeans.items():
	# 	est.fit(X)
	# 	print name
	# 	print est.labels_

	estimators_dpmeans = {'dp_means_1': dp_means(X, _lam=1),
						  'dp_means_5': dp_means(X, _lam=5),
						  'dp_means_5': dp_means(X, _lam=10)}
	for name, est in estimators_dpmeans.items():
		est.run()
		print name
		print est.dataClusterId
		print est.clusters



if __name__ == "__main__":
	main()